{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convertir el excel en dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5300, 121)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtener de los dos archivos excel \n",
    "# y juntar las bases de datos en un mismo dataframe\n",
    "import pandas as pd \n",
    "df1 = pd.read_excel('210_SIVIGILA Escritorio_01042008-30042023.xls')\n",
    "df2 = pd.read_excel('210_SIVIGILAweb_01052023-06082024 (1).xls')\n",
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5300, 121)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Ordenar los datos de acuerdo a los atributos de año y semana epidemiológica\n",
    "df = df.sort_values(by=['año', 'semana'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5300, 121)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Detección y eliminación de caracteres no implimibles en el dataset\n",
    "import re\n",
    "\n",
    "# Expresión regular para encontrar caracteres no imprimibles\n",
    "illegal_char_re = re.compile(r'[\\x00-\\x1F\\x7F-\\x9F]')\n",
    "\n",
    "def find_illegal_chars(df):\n",
    "    for col in df.columns:\n",
    "        for idx, val in df[col].items():\n",
    "            if isinstance(val, str) and illegal_char_re.search(val):\n",
    "                print(f\"Carácter ilegal encontrado en fila {idx}, columna '{col}': {repr(val)}\")\n",
    "\n",
    "\n",
    "# corregir aquí \n",
    "def remove_illegal_chars(val):\n",
    "    if isinstance(val, str):\n",
    "        return illegal_char_re.sub('', val)\n",
    "    return val\n",
    "\n",
    "df = df.map(remove_illegal_chars)\n",
    "df.shape \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bar_ver_\n",
       "9999999 SIN INFORMAC    203\n",
       "PUEBLO NUEVO            181\n",
       "ASOVIVIENDA             119\n",
       "SIN DATO                 59\n",
       "EL TRIANGULO             49\n",
       "                       ... \n",
       "ALTOS DEL COUNTRY         1\n",
       "BARRIO PORVENIR           1\n",
       "BARRIO COSTA DE ORO       1\n",
       "HACIENDA LA URIBE         1\n",
       "BR PAJONAL                1\n",
       "Name: count, Length: 463, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# contando los diferentes barrios y veredas que hay en el dataset original \n",
    "df.bar_ver_.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_barrios_correctos = ['PUEBLO NUEVO', 'CENTENARIO', \\\n",
    "                          'LAS VILLAS', 'EL TRIÁNGULO', 'EL BOSQUE', \\\n",
    "                          'PUEBLO SANTO', 'LOS ALMENDROS', 'EL DROMEDARIO', \\\n",
    "                          'EL CENTRO', 'VILLA ARABIA', 'CARACOLÍ', \\\n",
    "                          'VILLA GRANDA', 'ASOVIVIENDA', 'EL KENNEDY', \\\n",
    "                          'CLEMENTE ARRIETA', 'EL ÁGUILA', 'EL POBLADO', \\\n",
    "                          'SANTA ELENA', 'EL CAMELLO', 'LA ESPERANZA', \\\n",
    "                          'EL PRADO', 'SAN MIGUEL', 'SAN RAFAEL', \\\n",
    "                          'LA PAZ', 'LAS MALVINAS', 'EL CARMEN', \\\n",
    "                          'NUEVA ESTRELLA', 'LOMA FRESCA', 'EL ROBLE', \\\n",
    "                          'LA COLOMBIANITA', 'PARAGUAY', 'LA YE', \\\n",
    "                          'ALTOS DE SAN JUAN', 'PUERTO ESPAÑA', 'EL PALMAR', \\\n",
    "                          'LAS GAVIOTAS', 'ALTOS DE KIRIQUI', 'CASTILLITO', \\\n",
    "                          'LOS CÓRDOBA', 'EL LAGO', 'BUENO AIRES', \\\n",
    "                          'PEDRO VALDIVIA', 'SIN INFORMACION']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lista_barrios_correctos) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(3125)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cuantos datos nulos hay en ell atributo bar_ver_\n",
    "df['bar_ver_'].isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llene los datos faltantes con la cadena SIN INFORMACION\n",
    "df['bar_ver_'] = df['bar_ver_'].fillna('SIN INFORMACION') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['bar_ver_'].isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reemplazar los barrios mal copiados por nombres de barrios correctos\n",
    "import pandas as pd\n",
    "from difflib import get_close_matches\n",
    "\n",
    "# Lista de barrios correctos\n",
    "lista_barrios_correctos = ['PUEBLO NUEVO', 'CENTENARIO', 'LAS VILLAS', 'EL TRIÁNGULO', 'EL BOSQUE', \n",
    "                           'PUEBLO SANTO', 'LOS ALMENDROS', 'EL DROMEDARIO', 'EL CENTRO', \n",
    "                           'VILLA ARABIA', 'CARACOLÍ', 'VILLA GRANDA', 'ASOVIVIENDA', \n",
    "                           'EL KENNEDY', 'CLEMENTE ARRIETA', 'EL ÁGUILA', 'EL POBLADO', \n",
    "                           'SANTA ELENA', 'EL CAMELLO', 'LA ESPERANZA', 'EL PRADO', \n",
    "                           'SAN MIGUEL', 'SAN RAFAEL', 'LA PAZ', 'LAS MALVINAS', \n",
    "                           'EL CARMEN', 'NUEVA ESTRELLA', 'LOMA FRESCA', 'EL ROBLE', \n",
    "                           'LA COLOMBIANITA', 'PARAGUAY', 'LA YE', 'ALTOS DE SAN JUAN', \n",
    "                           'PUERTO ESPAÑA', 'EL PALMAR', 'LAS GAVIOTAS', 'ALTOS DE KIRIQUI', \n",
    "                           'CASTILLITO', 'LOS CÓRDOBA', 'EL LAGO', 'BUENO AIRES', \n",
    "                           'PEDRO VALDIVIA', 'SIN INFORMACION']\n",
    "\n",
    "def corregir_barrios(nombre):\n",
    "    if pd.isnull(nombre):\n",
    "        return 'SIN INFORMACION'\n",
    "    \n",
    "    # Convertir a cadena de texto\n",
    "    nombre = str(nombre).strip().upper()\n",
    "    \n",
    "    coincidencias = get_close_matches(nombre, lista_barrios_correctos, n=1, cutoff=0.8)\n",
    "    if coincidencias:\n",
    "        return coincidencias[0]\n",
    "    else:\n",
    "        return 'SIN INFORMACION'\n",
    "\n",
    "# Aplicar la corrección a la columna 'bar_ver'\n",
    "df['bar_ver_corregido'] = df['bar_ver_'].apply(corregir_barrios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verificación de la corrección del atributo bar_ver_  \n",
    "\n",
    "len(df.bar_ver_corregido.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5240, 122)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eliminar casos repetidos \n",
    "lista_atributos_criterio_igualdad = ['fec_not', 'semana', 'año','edad_',\\\n",
    "                                      'sexo_',\\\n",
    "                                      'bar_ver_corregido',\\\n",
    "                                          'telefono_', 'fecha_nto_']\n",
    "df = df.drop_duplicates(subset=lista_atributos_criterio_igualdad)\n",
    "df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertir el dataframe con los datos eliminados en un excel\n",
    "df.to_excel('datos_secretaria_con_casos_repetidos_eliminados.xlsx', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
